{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Useful Information\n",
    "*Curtis Miller*\n",
    "\n",
    "Now that we can download a webpage and read its data, we can start turning messy web data into clean data ready to be analyzed. The list we created in the last video can be used to visit Wikipedia pages, find and extract the data we need, and move on to the next page. (At this point you should be conscious about how fast your script runs, where being fast is **bad**, not good; use timers to slow down your script.)\n",
    "\n",
    "Let's first resume where we left off in the last video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from time import sleep\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "header = {\"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "          \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "          \"Connection\": \"keep-alive\",\n",
    "          \"Referrer\": \"https://www.google.com/\",\n",
    "          \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux i686; rv:54.0) Gecko/20100101 Firefox/54.0\"}\n",
    "\n",
    "# The URL we are visiting\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_Nobel_laureates\"\n",
    "page = session.get(url, headers=header).text\n",
    "nobelList = BeautifulSoup(page)\n",
    "\n",
    "nobelListTable = nobelList.find(\"table\", {\"class\": [\"wikitable\", \"sortable\"]})\n",
    "\n",
    "links = dict()    # Will contain names and links\n",
    "for node in nobelListTable.findAll(\"td\"):\n",
    "    if node.a != None and node.a.attrs[\"href\"][0:6] == \"/wiki/\":    # Avoids bad links\n",
    "        links[node.a.contents[0]] = node.a.attrs[\"href\"]   # Name: Link format\n",
    "\n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's design a scraper for the first page in this list, and hope that it will work for the other pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseurl = \"https://en.wikipedia.org\"\n",
    "\n",
    "baseurl + links[\"Aage Bohr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "person_page = session.get(baseurl + links[\"Aage Bohr\"], headers=header).text\n",
    "ppbsObj = BeautifulSoup(person_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look at the table with the birth date\n",
    "ppbsObj.find(\"table\", {\"class\": [\"infobox\", \"vcard\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ppbsObj.find(\"span\", {\"class\": \"bday\"})    # An easy way to grab the birthday; this is a class for span tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datetime.strptime(ppbsObj.find(\"span\", {\"class\": \"bday\"}).contents[0], \"%Y-%m-%d\")    # Fetching a birthday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After experimenting with a single page, we can extrapolate into a loop.\n",
    "\n",
    "If you look at the list of links you'll see links to organizations and some to footnotes. We try to find a birthdate but if none exists, or if the link is not what we want, then we should simply skip that entry and move on to the next.\n",
    "\n",
    "Additionally, our script should sleep between pages so it doesn't go too fast and overload Wikipedia's servers; here, my script sleeps for ten seconds (just to be safe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datadict = dict()\n",
    "for name, link in links.items():\n",
    "    sleep(10)    # Wait ten seconds between pages\n",
    "    print(\"Fetching: \" + name)\n",
    "    person_page = session.get(baseurl + links[name], headers=header).text\n",
    "    ppbsObj = BeautifulSoup(person_page)\n",
    "    bday_span = ppbsObj.find(\"span\", {\"class\": \"bday\"})\n",
    "    if bday_span != None:\n",
    "        try:\n",
    "            bday = datetime.strptime(bday_span.contents[0], \"%Y-%m-%d\")\n",
    "            datadict[name] = {\"Year\": bday.year,\n",
    "                              \"Month\": bday.month,\n",
    "                              \"Day\": bday.day}\n",
    "        except ValueError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datadict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nobelData = DataFrame(datadict).T\n",
    "nobelData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the visualizations we want to see when Nobel laureates were born."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nobelData.Month.value_counts().sort_index().plot(\"bar\")    # Month"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
